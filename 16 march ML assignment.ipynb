{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1: Define overfitting and underfitting in machine learning. What are the consequences of each, and how \n",
    "can they be mitigated ?\n",
    "\n",
    "Ans:\n",
    "(i) Overfitting -\n",
    "    Overfitting in ML occurs when a model learns the Training data too well Noise or random fluctuations\n",
    "    also capctured by model in data. that don't represent the underling patterns This can lead to poor \n",
    "    Generalization on new unseen data. isse Naye , Bina dekhe gaye data me Bekar Generalization ho sakti hai..\n",
    "\n",
    "    Consequences of Overfitting:- \n",
    "    1. Poor permformence on new data.\n",
    "    2. Sensitive to Noise in Training data. (Noise ke prati sensitive in training data.)\n",
    "    3. Limited applicability to real world scenarios.\n",
    "\n",
    "    Mitigations Stratigies for overfitting :-\n",
    "    1. Cross Validation - K-fold cross validation jaise Techniques ka use kren to assess model performence on\n",
    "                           different subset of the data.\n",
    "    2. Regularization - Apply techniques such as L1 or L2  regularization to penalize complex model and prevent \n",
    "                        overfitting.\n",
    "    3.Feature selection - Choose relevent features and eliminate irrelevent ones to reduce model complexity.\n",
    "\n",
    "(ii) Underfitting - \n",
    "     Underfitting on the other Hand , happens when a model is too simple to capcture the underlying patterns in training \n",
    "     data. it fails to learn relationships and performing pootly on both training and new data.\n",
    "\n",
    "     Consequences Underfitting:- \n",
    "     1. Inability to capcture complex patterns.\n",
    "     2. Low accuracy on both training and new data.\n",
    "     3. Model too generalised , laking predictive power. (Predictive power kam hoti hai.)  \n",
    "     \n",
    "     Mitigation strategies for underfitting :-\n",
    "     1. Feature Engineering :- Create more relevent features that better represent the problem.\n",
    "     2. Increase model complexity :- Use a more complex model or adjust hyperparameter to capcture underlying pattern.\n",
    "     3. Increasing the amount of training data can help the model better understand the underlying relationships.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: How can we reduce overfitting? Explain in brief.\n",
    "Answer2.\n",
    "Reducing overfitting in  ML involves implementing stratgies to prevent the model from fitting the training data too closely and improving its ability to generalize to new , unseen data.\n",
    "           techniques to reduce overfitting:-\n",
    "\n",
    "        1. Regularization :\n",
    "        Regularization Techniques , such as L1 , L2 regularization add penality terms in the loss function of Model based on the magnitude of its parameters.(L1 , L2 Punishment dete hai hai to our Model if they losses our data.) \n",
    "        \n",
    "        2. Cross validation :\n",
    "        Utilize Cross-validation methods , like k-fold cross validation , to assess the model's performence on different subsets of the training data (training data ke different subsets par models performence ka test karana.) this helps identify how well the model Generalizes to various data samples and prevents overfitting to specific instances.\n",
    "        \n",
    "        3. Feature selection :\n",
    "           Choose the most relevent features for training and discard irrelevant or redudant ones.this Reduces the complexity of the odel and helps prevent it from fitting noise in the data.\n",
    "\n",
    "        4. Reduce more complexity :\n",
    "         Simplyfy the model achitecture by reducing the number of layers , nodes or parameter. A less complex model is less prone to overfitting . (ek kam jatil model me overfitting ki possibility kam hoti hai.)\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: Explain underfitting. List scenarios where underfitting can occur in ML. \n",
    "\n",
    "Answer3.\n",
    "\n",
    "Underfitting : When a model is too simple to capcture the underlying patterns in Training data. The model fails to learn relationship between input features and target variables. \n",
    "\n",
    "list of those scnerios where underfitting can occur in ML.\n",
    "1. Low Data Avilability.\n",
    "2. Complex Relationship\n",
    "3. Inoppropiate Model complexity.\n",
    "4. Ignoring Relevent feature.\n",
    "5. Inadequate training.\n",
    "6. Improper Feature Scaling.\n",
    "7. Noise in data.\n",
    "8. Over Regularization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4: Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and \n",
    "variance, and how do they affect model performance?\n",
    "\n",
    "Answer: Bias Variance tradeoff is a critical concept in Machine learning. Yeh Tradeoff batata hai ki ek model kitni accurate hai aur usme kitni variability ya fluctuation hai.\n",
    "\n",
    "Bias :- Bias tab hota hai jab nodel bahut simplestic hota hai. aur training data ke underlying patterns ko capture nahi kar pata hai. jab ek model bahoot baised hota hai to vo data ke complexities ko ignore karta hai. Or ek Genral idea banata hai.\n",
    "\n",
    "Variance : Variance tab hota hai jab model bahoot complex hota hai or training data ke choote choote varitions ko bhi capture karne ki koshish karta hai. High Variance Ka matlab hota hai ki Model bahoot hi sensitive ho gaya hai or trainig data ke small changes ko bhi incorparate karta hai.\n",
    "\n",
    "Trade-off : Bias and variance trade-off ka matlab hota hai ki Hame model ko itna adjust karna hai ki wo data ke patterns ko acche se capture kar sake (Low Bias) and New data par bhi acche se genralize kare (Low Variance) .\n",
    "\n",
    "Overfitting me High Variance Hota hai and \n",
    "Underfitting me High Bias hota hai."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models. \n",
    "How can you determine whether your model is overfitting or underfitting? \n",
    "\n",
    "Answer: Detecting overfitting and underfitting is crusial in machine learning to ensure that your model generalize well to new and unseen data.\n",
    "\n",
    "Here are some common methods to detect these issus.\n",
    "\n",
    "Overfitting:\n",
    "\n",
    "(i) Validation curves.\n",
    "(ii) Learning Curves.\n",
    "(iii) Regularization\n",
    "(iv) Cross-Validation\n",
    "(v) Feature Importance.\n",
    "\n",
    "Underfitting:\n",
    "\n",
    "(i) Learning Curves.\n",
    "(ii) Validation Curves.\n",
    "(iii) Feature importance. \n",
    "(iv) Model Evaluation Metrics.\n",
    "(v) Increases Model Complexity.\n",
    "\n",
    "By using these Techniques you can know that your model do underfitting or not. \n",
    "By using right techniques you can improve gereralize performence of those model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6: Compare and contrast bias and variance in machine learning. What are some examples of high bias \n",
    "and high variance models, and how do they differ in terms of their performance?\n",
    "\n",
    "Answer: Bias and Variance are two key concepts in Machine learning. Who helps us to understand the source of error in predictive models. lets compare and difference between Bias and Variance.\n",
    "\n",
    "    Bias \n",
    "    Deffination: Bias ek real world problem ko bahut saral model dwara pratikriya dene se aaye khatre ko darshati hai.\n",
    "       [\"It is a difference between real output and predictive output.\"]\n",
    "\n",
    "    Properities:\n",
    "    High Bias model are generally too simple and data ko kam capture karta hai.\n",
    "    Ye Data me maujood patterns ko ignor kar sakte hai.\n",
    "    High Bias aksar Training and Test dataset par kharab performence dete hai. \n",
    "\n",
    "    Example: Linear regression with a limited number of features.\n",
    "             Ek chhota decision tree.\n",
    "\n",
    "    Variance\n",
    "    Defination:\n",
    "    Variance , model chhote flactuation ke prati kitna sensitive hai darshata hai.Variance darshata hai ki Model ki prediction kitni change ho rahi hai if we train our model to a different dataset's algorithm.\n",
    "\n",
    "    Properities:\n",
    "    High Variance models are more complex and training data ke deep patterns ko capture kar sakta hai.\n",
    "    Ye training dataset par acche se perform karta hai but new or unseen data par not performing well.\n",
    "    High variance overfitting la sakta hai jisme model training data se noise ko capture karta hai.\n",
    "\n",
    "    Example: A Deep Nural Network with many layers and parameters.\n",
    "             A Complex Polinomial Regression model.\n",
    "\n",
    "    Trade-off\n",
    "        Bias and variance ke beech ek tradeoff hota hai. Model ki complexity ko badhane par bias gatta hai. but variance badhta hai. aur ulta bhi hota hai. \n",
    "\n",
    "    Performence comparision\n",
    "\n",
    "    High Bias (Underfitting):\n",
    "                            Training data and test dataset dono par hi kharab performence deta hai.\n",
    "                            Failed to capture the underlying patterns of data.\n",
    "\n",
    "    High variance (Overfitting):\n",
    "                                Training dataset par performing well but not on test dataset.\n",
    "                                Training dataset me noise ko capture karta hai jisse ye kam Genarlizable ho jata hai.\n",
    "                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7: What is regularization in machine learning, and how can it be used to prevent overfitting? Describe \n",
    "some common regularization techniques and how they work.\n",
    "\n",
    "Answer:\n",
    "Regularization ML me ek technique hai jo overfitting se bachne ke liye use hoti hai. jab model training data par accha perform karta hai but test data par acche se perform nhi kar pata hai to isko rokne ke liye regularization model ke complexity ko controll karne ka ek tareeka hai. \n",
    "\n",
    "Some common Regularization Techniques - \n",
    "1. L1 Regularization (Lasso).\n",
    "2. L2 Regularzation (Ridge).\n",
    "3. Elastic Net Regularization.\n",
    "4. Drop out.\n",
    "5. Early stopping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
